{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FMML_CLF1_Lab2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/avivek5692/fmml2021/blob/main/FMML_CLF1_Lab2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ihr08YTg2ifn"
      },
      "source": [
        "# **FOUNDATIONS OF MODERN MACHINE LEARNING, IIIT Hyderabad**\n",
        "### MODULE: CLASSIFICATION-1\n",
        "### LAB-2 : Implement KNN from scratch and visualize algo. performance\n",
        "#### Module Coordinator: Sahil Manoj Bhatt\n",
        "\n",
        "NOTE: YOU ONLY NEED TO MAKE CHANGES/WRITE CODE IN CELLS THAT SPECIFICALLY MENTION TASK-1, TASK-2, etc.\n",
        "\n",
        "WRITE ANY OBSERVATION(S), IF REQUIRED BY THE TASK, IN A SEPARATE CELL AT THE BOTTOM OF THE NOTEBOOK.  \n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HIJdUKMs1QV0"
      },
      "source": [
        "## KNN\n",
        "\n",
        "In the last lab, you learnt distance metrics and their importance in classification algorithms. You also saw how the KNN algorithm works for two cases: i) a synthetic dataset and ii) a real-world Iris dataset.  \n",
        "\n",
        "However, the question still remains: *What is KNN?*  \n",
        "### What is KNN ?\n",
        "\n",
        "K-NN (K- Nearest Neighbours) is a classification technique where the output is a class membership.  \n",
        "An object is classified by a **plurality vote of its neighbors**, with the object being assigned to the class most common among its k nearest neighbors (k is a positive integer, typically small). If k = 1, then the object is simply assigned to the class of that single nearest neighbor.  \n",
        "\n",
        "### What is so unique about KNN ?  \n",
        "First off, KNN is a **supervised learning** algorithm, ie, the idea is to learn a function that can map an input to an output given some example pairs.  \n",
        "\n",
        "It is a **non-parametric** algorithm, since it doesn't assume anything about the form of the mapping function, which makes it very flexible to use. Certain algorithms are parametric (such as Naive Bayes), which are constrained as they require a specified form. KNN can, thus, be a good algorithm to try if the form is unknown.  \n",
        "\n",
        "Moreover, KNN is an **instance-based algorithm**, since it compares new problems/inputs with those which were seen during model training and that were stored in memory.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A7877e44n6Kd"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score#, precision_score, recall_score, f1_score,confusion_matrix,classification_report\n",
        "from sklearn import preprocessing\n",
        "from collections import Counter\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import warnings"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nHzdQE_8oPM1"
      },
      "source": [
        "def predict(X_train, y_train, X_test, k):\n",
        "    distances = []\n",
        "    targets = []\n",
        "\n",
        "    for i in range(len(X_train)):\n",
        "        # compute and store L2 distance\n",
        "        distances.append([np.sqrt(np.sum(np.square(X_test - X_train[i, :]))), i])\n",
        "\n",
        "    distances = sorted(distances)\n",
        "\n",
        "    for i in range(k):\n",
        "        index = distances[i][1]\n",
        "        targets.append(y_train[index])\n",
        "\n",
        "    # return most common target\n",
        "    return Counter(targets).most_common(1)[0][0]\n",
        "    # return k_nearest_neighbours and distances(1)[0][0]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9_kulEM0oWJ-"
      },
      "source": [
        "def k_nearest_neighbor(X_train, y_train, X_test, k):\n",
        "\n",
        "    assert k <= len(X_train), \"[!] K cannot be larger than number of samples.\"\n",
        "\n",
        "    # loop over all observations\n",
        "    predictions = []\n",
        "    for i in range(len(X_test)):\n",
        "        predictions.append(predict(X_train, y_train, X_test[i, :], k))\n",
        "\n",
        "    return np.asarray(predictions)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KlLazZsPbXml"
      },
      "source": [
        "# **Iris Dataset**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j7wJgGQOxbDv"
      },
      "source": [
        "Download the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 343
        },
        "id": "9gPMkdpxwq3k",
        "outputId": "c3c68dd8-6f13-4f65-b59e-c98828212ac8"
      },
      "source": [
        "# Upload the Iris data CSV file that has been shared with you.\n",
        "# Run this cell, click on the 'Choose files' button and upload the file.\n",
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-692634bc-fb8f-4902-a4e4-e7c962553717\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-692634bc-fb8f-4902-a4e4-e7c962553717\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "ename": "TypeError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-c0ebc758ee5d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# Run this cell, click on the 'Choose files' button and upload the file.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0muploaded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36mupload\u001b[0;34m()\u001b[0m\n\u001b[1;32m     66\u001b[0m   \u001b[0mlocal_filenames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m   \u001b[0;32mwhile\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'action'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'complete'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m     result = _output.eval_js(\n\u001b[1;32m     70\u001b[0m         'google.colab._files._uploadFilesContinue(\"{output_id}\")'.format(\n",
            "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i2KaMd3xxfVK"
      },
      "source": [
        "Explore the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MReMSexyoXj4"
      },
      "source": [
        "df = pd.read_csv('iris.csv')\n",
        "df = df.drop(columns='Id')\n",
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lI5ikdtwXICl"
      },
      "source": [
        "As you can see above, the last column consists of strings as classes. These need to be converted into appropriate numerical classes. For this, you can use the Label encoder module provided by scikit-learn.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3k-c7xhfpErX"
      },
      "source": [
        "le = preprocessing.LabelEncoder()\n",
        "orig_species = df['Species']\n",
        "le.fit(df['Species'])\n",
        "df['Species']=le.transform(df['Species'])\n",
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dWnZ-aQxUHmO"
      },
      "source": [
        "X = np.array(df[['SepalLengthCm','SepalWidthCm','PetalLengthCm','PetalWidthCm']])\n",
        "y = np.array(df['Species'])\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=17)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HczF_VrRpLGH"
      },
      "source": [
        "# Making our predictions\n",
        "predictions = k_nearest_neighbor(X_train, y_train, X_test, 7)\n",
        "\n",
        "# evaluating accuracy\n",
        "accuracy = accuracy_score(y_test, predictions)\n",
        "print(\"The accuracy of our classifier is {} %\".format(100*accuracy))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iwQ3qP-UXY5x"
      },
      "source": [
        "Voila! You have implemented your own version of the K-Nearest Neighbours algorithm, which works very well on the Iris Dataset. Congratulations!  \n",
        "\n",
        "Now try out the sklearn implementation and compare your results.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c0jJj5_7dg-o"
      },
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "sklearn_knn = KNeighborsClassifier(n_neighbors=7)\n",
        "sklearn_knn.fit(X_train,y_train)\n",
        "sklearn_predictions = sklearn_knn.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, sklearn_predictions)\n",
        "print(\"The accuracy of Sklearn classifier is {} %\".format(100*accuracy))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2hXZP4wXqtmK"
      },
      "source": [
        "## TASK-1\n",
        "## Modify the KNN function you wrote to return all the K-nearest neighbours along with their distances,\n",
        "## instead of just the output that was most common. You don't need to find out accuracy, just modify the function\n",
        "## and return the k-nearest neighbours and distances.\n",
        "def predict(X_train, y_train, X_test, k):\n",
        "    distances = []\n",
        "    targets = []\n",
        "\n",
        "    for i in range(len(X_train)):\n",
        "        # compute and store L2 distance\n",
        "        distances.append([np.sqrt(np.sum(np.square(X_test - X_train[i, :]))), i])\n",
        "\n",
        "    distances = sorted(distances)\n",
        "\n",
        "    for i in range(k):\n",
        "        index = distances[i][1]\n",
        "        targets.append(y_train[index])\n",
        "\n",
        "    # return most common target\n",
        "    # return Counter(targets).most_common(1)[0][0]\n",
        "    return k_nearest_neighbours and distances(1)[0][0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SxcBnLl8GHWz"
      },
      "source": [
        "## Visualizing Data  \n",
        "\n",
        "We will look into something called **Voronoi** diagrams.  \n",
        "\n",
        "**Note**: Ideally, we should perform data visualization to see what the data looks like before we apply any Machine Learning algorithm.  Only for the purpose of this lab session, we're explaining it after you've applied KNN."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4aDsDfmXG79k"
      },
      "source": [
        "### Voronoi Diagrams  \n",
        "\n",
        "In simple terms, Voronoi diagrams help you to visualize the dataset by partioning the plane into regions that are close to a given set of points. These regions are also called Voronoi cells.  \n",
        "\n",
        "Note that the cells/regions depend on the Distance metric being used. One way of interpreting this is by understanding that the distance metric decides the degree to which a 'point' or 'seed' in the Voronoi diagram has influence.  For each seed there is a corresponding region, called a Voronoi cell, consisting of all points of the plane closer to that seed than to any other. \n",
        "\n",
        "This [link](https://en.wikipedia.org/wiki/Voronoi_diagram#Illustration) provides a wonderful illustration of Voronoi plots for 20 points in two cases: (1) Using Euclidean distance, and (2) Using Manhattan distance.  \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AdcdjthOKwra"
      },
      "source": [
        "Since our Iris data is 4-dimensional (as it has 4 attributes), we need to convert into a form that can be represented in 2-D.   \n",
        "\n",
        "While there are methods to visualize data higher than 2-dimensions, that is beyond scope for now.  \n",
        "\n",
        "For simplicity, we just take the first two columns of the iris dataset attributes and observe the Voronoi diagram generated for that.  \n",
        "Alternatively, one can also perform PCA (Principal Component Analysis), to reduce the 4D data to just two dimensions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZNOPcS3f7sZg"
      },
      "source": [
        "#@title Plotting Voronoi regions\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.spatial import Voronoi, voronoi_plot_2d\n",
        "\n",
        "def voronoi_finite_polygons_2d(vor, radius=None):\n",
        "    \"\"\"\n",
        "    Reconstruct infinite voronoi regions in a 2D diagram to finite\n",
        "    regions.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    vor : Voronoi\n",
        "        Input diagram\n",
        "    radius : float, optional\n",
        "        Distance to 'points at infinity'.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    regions : list of tuples\n",
        "        Indices of vertices in each revised Voronoi regions.\n",
        "    vertices : list of tuples\n",
        "        Coordinates for revised Voronoi vertices. Same as coordinates\n",
        "        of input vertices, with 'points at infinity' appended to the\n",
        "        end.\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    if vor.points.shape[1] != 2:\n",
        "        raise ValueError(\"Requires 2D input\")\n",
        "\n",
        "    new_regions = []\n",
        "    new_vertices = vor.vertices.tolist()\n",
        "\n",
        "    center = vor.points.mean(axis=0)\n",
        "    if radius is None:\n",
        "        radius = vor.points.ptp().max()\n",
        "\n",
        "    # Construct a map containing all ridges for a given point\n",
        "    all_ridges = {}\n",
        "    for (p1, p2), (v1, v2) in zip(vor.ridge_points, vor.ridge_vertices):\n",
        "        all_ridges.setdefault(p1, []).append((p2, v1, v2))\n",
        "        all_ridges.setdefault(p2, []).append((p1, v1, v2))\n",
        "\n",
        "    # Reconstruct infinite regions\n",
        "    for p1, region in enumerate(vor.point_region):\n",
        "        vertices = vor.regions[region]\n",
        "\n",
        "        if all(v >= 0 for v in vertices):\n",
        "            # finite region\n",
        "            new_regions.append(vertices)\n",
        "            continue\n",
        "\n",
        "        # reconstruct a non-finite region\n",
        "        ridges = all_ridges[p1]\n",
        "        new_region = [v for v in vertices if v >= 0]\n",
        "\n",
        "        for p2, v1, v2 in ridges:\n",
        "            if v2 < 0:\n",
        "                v1, v2 = v2, v1\n",
        "            if v1 >= 0:\n",
        "                # finite ridge: already in the region\n",
        "                continue\n",
        "\n",
        "            # Compute the missing endpoint of an infinite ridge\n",
        "\n",
        "            t = vor.points[p2] - vor.points[p1] # tangent\n",
        "            t /= np.linalg.norm(t)\n",
        "            n = np.array([-t[1], t[0]])  # normal\n",
        "\n",
        "            midpoint = vor.points[[p1, p2]].mean(axis=0)\n",
        "            direction = np.sign(np.dot(midpoint - center, n)) * n\n",
        "            far_point = vor.vertices[v2] + direction * radius\n",
        "\n",
        "            new_region.append(len(new_vertices))\n",
        "            new_vertices.append(far_point.tolist())\n",
        "\n",
        "        # sort region counterclockwise\n",
        "        vs = np.asarray([new_vertices[v] for v in new_region])\n",
        "        c = vs.mean(axis=0)\n",
        "        angles = np.arctan2(vs[:,1] - c[1], vs[:,0] - c[0])\n",
        "        new_region = np.array(new_region)[np.argsort(angles)]\n",
        "\n",
        "        # finish\n",
        "        new_regions.append(new_region.tolist())\n",
        "\n",
        "    return new_regions, np.asarray(new_vertices)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9NIVhxz8KvG3"
      },
      "source": [
        "## Plotting Voronoi regions for the Iris dataset\n",
        "\n",
        "points = []\n",
        "xpts = np.array(df['SepalLengthCm'])\n",
        "ypts = np.array(df['SepalWidthCm'])\n",
        "for i in range(len(xpts)):\n",
        "  points.append([xpts[i],ypts[i]])\n",
        "print(points)\n",
        "points = np.array(points)\n",
        "# compute Voronoi tesselation\n",
        "vor = Voronoi(points)\n",
        "\n",
        "regions, vertices = voronoi_finite_polygons_2d(vor)\n",
        "\n",
        "for region in regions:\n",
        "    polygon = vertices[region]\n",
        "    plt.fill(*zip(*polygon), alpha=0.4)\n",
        "\n",
        "plt.plot(points[:,0], points[:,1], 'ko')\n",
        "plt.xlim(vor.min_bound[0] - 0.1, vor.max_bound[0] + 0.1)\n",
        "plt.ylim(vor.min_bound[1] - 0.1, vor.max_bound[1] + 0.1)\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WSK-GI0Knurk"
      },
      "source": [
        "## Understanding Decision Boundaries  \n",
        "So you have seen the Voronoi diagram of the dataset, implemented KNN, and also seen your algorithm's performance in terms of accuracy? Impressive!  \n",
        "Wouldn't it also be great to know how exactly these 'votes' or neighbours are decided through some kind of visualization?  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ytP_AImALiZX"
      },
      "source": [
        "### Decision Boundary\n",
        "\n",
        "While the Voronoi diagram gave us a good idea of the points present in our dataset, to understand how KNN performed on our dataset we can plot decision boundaries. Decision boundaries, as the name suggests, divide the plane into different regions of classification.  \n",
        "\n",
        "Note that here again, for simplicity, we have only considered first two attributes of the DataFrame (ie, Sepal Length and Sepal Width).  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8P8Pqav4DI4N"
      },
      "source": [
        "from matplotlib.colors import ListedColormap\n",
        "import seaborn as sns\n",
        "\n",
        "\n",
        "def decision_boundary_plot(x_dec,y_dec,k):\n",
        "  h = .02  # step size in the mesh\n",
        "\n",
        "  # Create color maps\n",
        "  n = len(set(y_dec))\n",
        "  cmap_light = ListedColormap(['pink', 'green', 'cyan','yellow'][:n])\n",
        "  cmap_bold = ['pink', 'darkgreen', 'blue','yellow'][:n]\n",
        "\n",
        "  for weights in ['uniform', 'distance']:\n",
        "      # we create an instance of Neighbours Classifier and fit the data.\n",
        "      clf = KNeighborsClassifier(n_neighbors=k, weights=weights)\n",
        "      clf.fit(x_dec, y_dec)\n",
        "\n",
        "      # Plot the decision boundary. For that, we will assign a color to each\n",
        "      # point in the mesh [x_min, x_max]x[y_min, y_max].\n",
        "      x_min, x_max = x_dec[:, 0].min() - 1, x_dec[:, 0].max() + 1\n",
        "      y_min, y_max = x_dec[:, 1].min() - 1, x_dec[:, 1].max() + 1\n",
        "      xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
        "                          np.arange(y_min, y_max, h))\n",
        "      Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
        "\n",
        "      # Put the result into a color plot\n",
        "      Z = Z.reshape(xx.shape)\n",
        "      plt.figure(figsize=(8, 6))\n",
        "      plt.contourf(xx, yy, Z, cmap=cmap_light)\n",
        "\n",
        "      # Plot also the training points\n",
        "      sns.scatterplot(x=x_dec[:, 0], y=x_dec[:, 1], hue=y_dec,\n",
        "                      palette=cmap_bold, alpha=1.0, edgecolor=\"black\")\n",
        "      plt.xlim(xx.min(), xx.max())\n",
        "      plt.ylim(yy.min(), yy.max())\n",
        "      plt.title(\"Multi-Classification (k = %i, weights = '%s')\"% (k, weights))\n",
        "\n",
        "  plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bgAO62vWKPHt"
      },
      "source": [
        "x_pts = X[:,:2]\n",
        "y_pts = y\n",
        "decision_boundary_plot(x_pts,y_pts,7)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TFRJidIgr6gt"
      },
      "source": [
        "## TASK-2\n",
        "## In the above cells, we saw the Voronoi diagram of the data and plotted the KNN decision boundaries\n",
        "## by only considering two attributes of the dataset. You must be already familiar with PCA.\n",
        "## Apply PCA on the dataset above to reduce it to two dimensions. \n",
        "## Plot the Voronoi diagram and Decision boundaries after that.\n",
        "df.isnull().sum()/len(df)*100\n",
        "a = df.isnull().sum()/len(df)*100\n",
        "# saving column names in a variable\n",
        "variables = df.columns\n",
        "variable = [ ]\n",
        "for i in range(0,5):\n",
        "  if a[i]<=20:\n",
        "    variable.append(variables[i])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gti-Jgu_VBDl"
      },
      "source": [
        "## Confusion Matrix  \n",
        "In classification problems, a confusion matrix, also known as an error matrix, is a table that allows visualization of the performance of an algorithm, typically a supervised learning one. Each row of the matrix represents the instances in an actual class while each column represents the instances in a predicted class."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LPfc8YFBA8Oh"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XMXIM9apA99s"
      },
      "source": [
        "print(confusion_matrix(y_test,predictions))\n",
        "pd.crosstab(y_test, predictions, rownames=['True'], colnames=['Predicted'], margins=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5cgYG0E5UHdy"
      },
      "source": [
        "from sklearn import metrics\n",
        "\n",
        "cnf_matrix = metrics.confusion_matrix(y_test, predictions)\n",
        "p = sns.heatmap(pd.DataFrame(cnf_matrix), annot=True, cmap=\"viridis\" ,fmt='g')\n",
        "plt.title('Confusion matrix', y=1.1)\n",
        "plt.ylabel('Actual label')\n",
        "plt.xlabel('Predicted label')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TTPQOPStVtmI"
      },
      "source": [
        "## Classification Report\n",
        "\n",
        "Precision, Recall, and F1-Score are other metrics besides accuracy that one might look for in an algorithm.  Depending on the use-case, one might consider one metric more important than the other.  \n",
        "\n",
        "Note: *T-> True, F->False, P->Positive, N->Negative*\n",
        "    \n",
        "Mathematically, Accuracy is :  \n",
        "\n",
        "$Accuracy = \\frac{TP+TN}{TP+TN+FP+FN}$  \n",
        "\n",
        "**Precision**: The accuracy of positive predictions\n",
        "\n",
        "\n",
        "$Precision = \\frac{TP}{TP+FP}$ \n",
        "\n",
        "**Recall**:Fraction of positives that were correctly identified\n",
        "\n",
        "\n",
        "$Recall = \\frac{TP}{TP+FN}$\n",
        "\n",
        "\n",
        "**F1-score**: Harmonic mean of precision and recall  \n",
        "\n",
        "\n",
        "$F1 = \\frac{2*Precision*Recall}{Precision+Recall} = \\frac{2*TP}{2*TP+FP+FN}$  \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VH3KEfEYW190"
      },
      "source": [
        "# import classification_report\n",
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_test,predictions))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YtYNFoJh0LU-"
      },
      "source": [
        "# **Car Evaluation Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RsBukCMi4UjJ"
      },
      "source": [
        "# Upload the Car evaluation data CSV file that has been shared with you.\n",
        "# Run this cell, click on the 'Choose files' button and upload the file.\n",
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0T5yvzVH4jrQ"
      },
      "source": [
        "car_df = pd.read_csv('car_evaluation.csv')\n",
        "car_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qwjBankjB9Os"
      },
      "source": [
        "for x in car_df.columns:\n",
        "  print(x)\n",
        "  le = preprocessing.LabelEncoder()\n",
        "  le.fit(car_df[x])\n",
        "  car_df[x]=le.transform(car_df[x])\n",
        "\n",
        "car_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W5Klx4yMCgKa"
      },
      "source": [
        "dataset = car_df.values\n",
        "X = dataset[:,0:6]\n",
        "y = np.array(dataset[:,4])\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=19)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1HL5ufCHDANh"
      },
      "source": [
        "knn = KNeighborsClassifier(n_neighbors=5)\n",
        "knn.fit(X_train, y_train)\n",
        "predictions = knn.predict(X_test)\n",
        "score = accuracy_score(y_test, predictions)\n",
        "print(\"The accuracy of the classifier on Car evaluation dataset is {:.2f} %\".format(100*score))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "score"
      ],
      "metadata": {
        "id": "Jrvc1yIW04gX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WYCimUC_A56C"
      },
      "source": [
        "## TASK-3\n",
        "## Plot a Confusion Matrix for the results of the Car evaluation dataset\n",
        "print(confusion_matrix(y_test,predictions))\n",
        "car_df = pd.DataFrame(score, index = [i for i in range(0,6)], columns = [i for i in range(0,6)])\n",
        "plt.figure(figsize=(10,8))\n",
        "sns.heatmap(car_df,annot=True)\n",
        "plt.title('KNN \\nAccuracy:{0:.4f}'.format(accuracy_score(y_test,predictions)))\n",
        "plt.ylabel('True label')\n",
        "plt.xlabel('Predicted label')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a8TRknp0XTqJ"
      },
      "source": [
        "## TASK-4\n",
        "# Print a Classification Report for the results of the Car evaluation dataset\n",
        "print(classification_report(y_test, predictions))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xr9dI1Kqsprz"
      },
      "source": [
        "### Questions to Think About and Answer\n",
        "1. In the section on Decision boundaries, you must have seen that we ran the KNN algorithm twice: first with the _weights_ set to 'uniform' and then set to 'distance'. Find out the difference between these two.  \n",
        "2. What do you think could be the drawbacks of using KNN ?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TRlrn4EctZrC"
      },
      "source": [
        "### Useful Resources for further reading\n",
        "1. Interactive KNN visualization, with class boundaries: http://vision.stanford.edu/teaching/cs231n-demos/knn/  \n"
      ]
    }
  ]
}